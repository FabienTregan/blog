= Tests d'intégration et services: ce qu'il faut savoir pour que ça se passe bien

Sous-titre "Des points d'attentions et des suggestions pour améliorer les chose"

## De quoi parle-t-on ?

Si votre système d'information comprend des échanges entre applications,
que cela soit sous forme de services de messages ou de fichiers, il est probable que vous testiez ces dépendances à l'aide de tests d'intégration.
Ils permettent de valider les comportements dans des conditions aussi proches que possible des conditions réelles.

Si vous ne pratiquez pas le link:http://blog.octo.com/continuous-deployment/[déploiement continu], ces tests sont souvent source de tensions entre projets :
aux difficultés inhérentes aux bugs d'intégrations (de quels côté est le problèmes ?) s'ajoutent les contraintes de calendrier et d'indisponibilité.
Ce n'est pas une fatalité, si les tests d'intégrations sont toujours un point d'attention, les choses peuvent bien se passer.

L'objectifs de cet article est de vous aider à améliorer la situation en vous indiquant les points d'attentions à surveiller et les antipatterns à éviter.
Pour cela nous allons commencer par parler gouverance, puis la question des données, pour terminer sur le déploiement des applications.

## Gouvernance

Les tests d'intégrations est l'étape où on commence à assembler les briques applicatives unitaires pour construire un SI.
On passe donc du chacun pour soi, à un système commun.

Chaque application a tendance à se concentrer sur ses propres besoins tout en négligeant ceux des autres : elle se voit seule au monde à faire ses tests et les autres qui sont là pour elle, sans réaliser que pour les autres la situation est exactement la même.
Il est donc normal que des problèmes de gouvernance s'y posent,
et que des arbitrages soient nécessaires.

### Garantir une qualité de service

Lorsqu'une équipe fait ses tests d'intégration, elle demande que toutes les applications dont elle a besoin fonctionnent pour pouvoir avancer le plus vite possible.
Le problème est que souvent on ne s'applique pas à soi-même  le niveau d'exigence qu'on fait peser sur les autres équipes:
on râle quand on est bloqué par quelqu'un d'autre, mais sans faire en sorte que nos propres applications soit en permanence accessible, sans comprendre qu'en agissant ainsi on reproduit le problème pour les autres.

Il est possible d'améliorer la situation en mettant en place une garantie de service (SLA), un peu comme en production.
Il ne s'agit pas de dire que les environnements d'intégration sont aussi critiques que la production, mais d'acter qu'une interruption de service en intégration est suffisament domageable pour que les interruptions soient traitées avec l'urgence nécessaire, sans qu'il y ait besoin d'avoir à argumenter ou escalader.

TIP: Cela permet également d'utiliser les mêmes outils de monitoring et d'alerting qu'en production, ce qui permet de les tester en même temps que le reste des applications.

Toute interruption de service pour maintenance doit alors être communiquée et validée, donc plus questions de décider qu'une application sera indisponible pendant une semaine le temps de tester une mise à jour ou un nouvel outil.

La garantie s'étend bien entendu aux différents middleware (sécurité, intégration…): plus question de faire des tests "unitaires" en environement d'intégration, ou de ne faire que des tests d'intégrations au risque de bloquer tout les autres.
Chaque brique, même non applicative, doit avoir son propre environnement de test "unitaire" et ses jeux de tests qui permettent de valider le maximum de choses de manière indépendante.

### Aider aux investigations

Pendant les tests d'intégration, on rencontre régulièrement des problèmes à la frontières entre les applications et qui peuvent être difficiles à diagnostiquer.

Pendant la phase d'investigation, on ne sait pas forcément quelle est la source du bug et on peut ainsi avoir besoin de l'aide de toutes les équipes, sans être certain que le problème vienne de son côté.

Quand une bonne entente règne entre les équipes, chacune fournit son aide sans trop se faire tirer l'oreille.
À l'inverse, quand la situation est plus tendue, par exemple quand chaque équipe est objectivée sur son avancement propre plutôt que sa contribution globale, les équipes aideront moins volontier les autres.

Cela se matérialise par le fait de faire trainer les choses en espérant que ça se tasse, et/ou de demander des preuves que le problème vient de leur côté.
Cela ralentit tout le système tout en créant de la frustration, et à long terme peut entrainer la création d'un cercle vicieux.

Une bonne gouvernance fera donc en sorte que les projets soient bien disposés à participer aux efforts d'investigations communs.
Cela passe par le fait d'accepter que ces tâches prennent du temps, et réduisent donc la capacité à faire des équipes.

TIP: Si une équipe se plaint de passer trop de temps à aider aux investigations, c'est souvent le signe qu'elle n'investit pas assez dans les outils (monitoring et log) qui lui permettrait d'être plus efficace ou de permettre aux autres d'êtres autonomes.
Ces mêmes outils serviront ensuite pour aider à diagnostiquer des problèmes en productions, il s'agit donc d'un investissement rentable.


### Prioriser les corrections d'erreur

Une fois une investigation terminée et une erreur identifiée, reste à la corriger.

Toutes les équipes ont une procédure, officielle ou officieuse, pour corriger rapidement les bugs bloquant lorsqu'ils apparaissent lors des tests d'intégration.
Malheuresement cette action est souvent plus beaucoup difficile à activer lorsqu'il s'agit d'un bug qui bloque quelqu'un d'autre.

Cela ne veut pas dire qu'il faut utiliser systématiquement cette procédure d'urgence, mais que "est ce que ça nous gène nous ou quelqu'un d'autre ?" ne devrait pas faire partie des critères permettant de décider ou non de l'appliquer.

## PLAN

## Applications et environnements de recette

* Recette : tester pour soi et pour les autres
** Aspect de haute dispo : si pas possible de faire de test le projet est bloqué
** Éviter d'avoir à programmer les tests de recette
** Les autres doivent être dispo pour mes tests
** Je dois être dispo pour les tests des autres
* J'ai besoin de pouvoir tester la version en cours pour la maintenance et la version suivante pour les évolutions
* Les autres ont besoin de pouvoir tester la version en cours et la version suivante
* Schéma qui montre deux instances de chaque application, avec bascule
* Cas de cycles de développement très courts
** Seule la version courante des applis est dispo pour les autres

### Mono-instance

image::mono.png[]

### Instances en parallèle

image::bi.png[]

## Quelles données pour les tests ?

Une fois décidé de la manière de déployer les applications, reste le sujet des données à utiliser pour les tests.

### Un système distribué a des incohérences de données

Le premier point et que, quelque soit la manière dont vous vous y prenez, vous aurez des incohérences de données entre vos systèmes.
Dès qu'un système est distribué, ce problème est là.
Les environements d'intégrations, avec des applications en cours de tests (donc avec plus de bugs) et des bidouilles sur les données, sont un terreau fertile pour qu'ils apparaissent.

La meilleure stratégie face à cela est d'accpter la réalité de la situation, c'est à dire que le problème est là, et s'y confronter.

Cela veut dire rendre vos systèmes robustes, ce qui ne veut pas dire bidouiller les données ou ignorer les erreurs, mais avoir un monitoring et un reporting qui vous permettent de les identifier rapidement et pouvoir effectuer des corrections propres.

La bonne nouvelle est que cet investissement vous servira également en production, est lorsqu'un problème de donnée bloquera vos système, vous serez bien content d'avoir pris auparavant le temps de vous outiller pour vos tests.

### Utiliser des données de production

### Utiliser des données de référence

## PLAN

* Besoins
** Tester les différents cas
** Ne pas passer trop de temps à les maintenir
* 2 approches
** Données de production
	** Solution de facilité
	** Problèmes de l'anonymisation
	** Problème de filtrage (on ne remonte pas toutes les données)
	** Problème d'avoir les données qu'on veut pour tester tous les cas
** Données de référence pour chaque projet
	** Simplifie les tests car on connait les valeurs
	** Demande un travail continu de mis à jour
	** Demande une synchronization entre les projets pour avoir des données cohérentes
	** Peut être aussi utile pour les tests unitaires et pour les mocks

## Comment faire ?

* Un environnement commun
** Approche la plus simple
** Problème de données et de dispo
* Un environnement complet pour chaque projet = ensemble des applications autour et des middleware
** Permet à chacun de faire ses tests de manière autonome
** Nécessite des middleware bien adaptés
** Les développeurs deviennent éditeur d'un logiciel
	** Nécessite des applis bien packagées et faciles à utiliser
		** Les autres applis sont capable de diagnostiquer les erreurs sans demander à un de tes développeirs
	** Si bien fait = améliore la qualité des livrables et des process
	** Mais un projet qui fait mal son boulot fait souffrir les autres
		** Demande une pression hiérarchique

'''
[TIP]
.À retenir
====

- Chaque équipe a tendance à s'intéresser à ses besoins et à négliger ceux des autres, une bonne gouvernance permet d'en limiter les conséquences néfastes.
- Vous aurez des problèes d'incohérence de données, mais si vous vous outillez pour bien les résoudre, vous pourrez utiliser les mêmes outils en production.

====
