= Le DataLab et le SI : quelques sujets d'architecture de SI qui fâchent
Julien Kirch
v0.1, 2019-01-31
:article_lang: fr

WARNING: ⚠️WIP⚠️️️️

== De quoi parle-t-on ?

La mise en place un DataLab en production peut déjà link:https://www.octo.com/fr/evenements/183-levez-la-malediction-du-passage-de-l-ia-en-production[être un défi].

Ensuite vient le moment de faire vivre sur le moyen et long terme ce qui vient d'être déployé.
Voici quelques exemples de ce que j'ai pu entendre en mission sur ce sujet.

[quote]
____
Pour le DataLab on s'est branché aux bases de données des différents projets, du coup chaque fois que leurs schémas changent pendant une MEP le week-end ça casse notre code d'import et on doit se dépêcher de réparer le lundi matin.
____

[quote]
____
Le métier est très content des premiers résultats sur le _churn_, mais pour améliorer les modèles il faudrait corriger des problèmes de qualité de données dans les projets amont, mais on n'arrive pas à se faire entendre.
____

[quote]
____
Pour aller plus vite on a branché le Lab sur la BI.
Ça a été super cool pour démarrer, mais on a vendu du temps réel et la BI est en J+1 et maintenant on ne sait pas comment faire.
____

Vous l'avez compris : si vous pensez que déployer le code en production est le plus difficile, j'ai une mauvaise nouvelle pour vous.

Rasurez vous : il existe des solutions pour éviter d'aboutir aux situations que je viens de décrire.
Ces solutions ne sont pas forcément faciles à mettre en œuvre, mais -- en attendant de trouver mieux -- elles peuvent fonctionner..

== Pour POCer tout peut-être est permis, sauf se mentir

Tout d'abord les POCs : quand il s'agit de tester des hypothèses pour les valider, par exemple la perinence de croiser plusieurs sources de données pour améliorer une offre commerciale, travailler avec des contraintes allégées est souhaitable par rapport à un projet de "`run`".

Le sujet de l'article n'est pas d'ajouter des contraintes -- et donc de freiner -- les expérimentations.

Ainsi travailler sur un laptop à partir d'export manuel de données peut être le meilleur choix dans certaines situations.

Mais par contre attention à ne pas se bercer d'illusions : si ces contraintes existent, c'est généralement pour de bonnes raisons.

Ce qui signifie qu'il faut garder en tête qu'un jour où l'autre il faudra s'y confronter, que ça soit pour les appliquer ou pour ne pas les appliquer mais d'une manière satisfaisante, par exemple en ayant convaincu ou du moins obtenu l'accord des bonnes personnes.

C'est pour cela que je parle de contraintes _allégées_ et pas de ne pas avoir de contraintes du tout :
si l'objectif d'un POC est de prouver la faisabilité d'une certaine approche, prendre en compte certaines des contraintes de production peut être pertinent si vous savez à l'avance que les ignorer pourrait rendre impossible, ou trop compliqué, le déploiement en production.
C'est l'un des éléments à prendre en compte pendant la phase de cadrage.

Cela peut-être le cas si votre POC nécessite un certain type de matériel ou d'un logiciel qui est incompatible avec votre environnement, ou que son approche est incompatible avec le RGPD.

Réfléchissez donc bien aux concepts qu'un POC doit prouver, et quels sont les critères permettant de juger qu'il y soit parvenu.

== Quand vient le moment de s'intéresser à la production

Une fois qu'un POC a fait ses preuves, il est temps de s'intéresser aux critères de passage en production.

L'article traitant d'architecture de SI, je ne parlerai pas des sujets liés à la qualité du code commes les tests automatisés ou les revues de code.
Cela ne veut pas dire qu'elles sont moins importantes mais qu'elle ne sont pas notre sujet ici.

En dehors des questions d'architecture en elles-mêmes, le premier problème est celui de faire passer le projet d'un mode POC à un mode _production-ready_.

Quand on a un POC qui fonctionne, on a envie d'aller vite en production pour pouvoir exploiter ce qui a été réalisé, surtout que du point de vue des résultats visibles, la production peut ne rien apporter.

WARNING: ⚠️En dessous c'est juste le plan⚠️️️️

problème d'avoir du budget et du temps aloué, et la volonté de le faire, surtout si le projet a été hébergé dans un lab et/ou est porté par un sponsor plutôt rétif

Les projet de datascience ne sont pas des projets d'informatique de gestion classique, il peut etre pertinent d'essayer de bouger certaines règles, mais ça demande de négocier, tenter de passer sous le radar est tentant mais sérieux

rappellez-vous que les sujets d'intégration concernent les données, c'est à dire la matière première de votre système : avoir de mauvaises données ou se retrouver sans données et votre projet devient inutile

== Les axes

=== Pérénité de l'intégration

Branchement aux applis qui fournissent de la donnée = couplage = ça peut casser

=== Vitesse de captation des données

CVS par batch de nuit ou branchemet à la BI ça peut répondre à certains besoins, mais ça peut limiter les uses cases adressés

=== Qualité des données

Données pourries car ce n'est pas un problème en amont, ça peut être des problèmes tech ou métier (mauvaises saisies)

Ça peut etre des problèmes locaux aux applications, ou des problèmes de cohérences entre applications

== Les solutions

Malheuresement les solutions vont passer par des demandes aux projets, après le POC un DataLab ne peut pas se faire en mode shadow IT.

=== Intégration

* Mode d'intégration le plus pérenne possible (genre pas par la base)
* Faire des tests automatisés d'import sur les environnements de recette voire avant, et que ça soit le problème du projet amont
* Avoir quelqu'un qui s'intéresse au sujet dans les projets

=== Vitesse de captation

Enjeu majeur car ça dimensionne la complexité des projets

On peut avoir des solutions pour le lab avec plein de données "en retard" qui permet de tester, et une autre pour la prod, avec des données moins riches mais rapide

Solution la meilleure : reposer sur des envois de message en fil de l'eau, mais c'est très impactant pour les projets amonts

=== Qualité des données

Trouver des relais dans les projets, et un relai compatible avec la capacité d'innovation ciblée par le lab, au moins sur la capacité à avoir des réponses sur le temps de correction.

La gouvernance de donnée, qu'on pouvait éviter de mettre en œuvre tant que les données restaient silotées, revient au goût du jour.

Après il faut une volonté métier, voire une volonté de la direction : si le lab a pour vocation des données de toutes l'orga, elle va toucher des projets de tous les métiers, et va donc demander un bon sponsoring pour ne pas s'épuiser

== Conclusion

Pour POCer un DataLab tous les moyens sont bons, mais attention à ne pas se mentir sur le RAF ensuite pour en faire un asset mature du SI : il faut sortir su shadow IT.

Un DataLab qui veut manipuler toutes les données du SI va demander un effort d'intégration conséquent.

Étendre son périmètre va demander un effort sur la qualité de la donnée dans le SI, ce qui a des impacts projets et souvent métier.

Péréniser son fonctionnement va demander un effort d'industrialisation sur la manière dont les données sont mises à disposition, et de gouvernance projet pour éviter les mauvaises surprises.