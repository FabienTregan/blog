[#MDT-07]
= Partie 7 : {article-07-nom}

Pour le moment, quand le {mdt} est lancé il commence à traiter des tâches, et s'arrête quand il n'y en a plus.
Si j'ajoute des tâches après-coup, il ne se passe rien.
En effet une fois les workers en pause, aucun mécanisme ne les réveille quand d'autres tâches sont insérées dans la base de données.

L'un des avantage de l'utilisation de bus de messages comme ActiveMQ ou Kafka pour stocker les tâches d'une {mdt} par rapport à une base de données traditionnelle vient de leur fonctionnalités de notification, où le code du moteur peut écouter des évènements (ici les tâches qui sont ajoutées) envoyés par le bus, pour déclencher le traitement des tâches.

Redis fournit également ce type de méchanisme, mais c'est aussi le cas pour PostgreSQL à travers les fonctions link:https://www.postgresql.org/docs/current/sql-listen.html[`LISTEN`] et link:https://www.postgresql.org/docs/current/sql-notify.html[`NOTIFY`].

== Le principe des notifications

Lorsque les worker sont en train de tourner, après avoir terminé une tâche ils vont en chercher une autre, même si cette dernière a été ajoutée après le démarrage du {mdt}. Dans ce cas il n'y a rien de spécial à faire.

Par contre, lorsqu'au moins un des workers s'est arrêté car il n'a pas trouvé de tâche disponible, il faut le solliciter pour qu'il se remette au travail quand une nouvelle tâche est créée.

Cela permet que la nouvelle tâche soit traitée au plus vite, plutôt que d'attendre qu'un worker qui est déjà en train d'exécuter une autre tâche ne la termine.

Lorsqu'on insère une nouvelle tâche, il faudra donc envoyer une notification pour réveiller les worker qui pourraient être disponibles.

Pour cela j'utiliserai un thread supplémentaire qui sera chargé d'écouter les notifications envoyées pour réveiller les workers.

En Ruby, la classe link:https://ruby-doc.org/core-2.7.0/Queue.html[Queue] est destinée à ce type d'usage où des thread doivent s'attendre et communiquer entre eux.
Il s'agit d'une file (une sorte de liste dont les éléments sortent dans le même ordre que celui où ils sont insérés), à laquelle plusieurs threads peuvent accéder en parallèle.
Le comportement le plus intéressant pour un {mdt} est que si du code demande à récupérer un élément de la queue alors qu'elle est vide, le thread correspondant se mettra en attente jusqu'à ce qu'un élément soit disponible.

Il serait possible de manipuler directement les thread des workers comme pour l'arrêt du {mdt}, en passant les thread des workers en le statut `sleep` puis en les réveillant avec `Thread#wakeup`, mais `Queue` fournit une API prête à l'emploi pour cela, et cela évite d'avoir le genre de bugs pénibles qui apparaît quand on décide de réinventer la roue sur un sujet qui touche au threading.

Il faut garder en tête que le fonctionnement final doit être compatible avec le fait d'avoir plusieurs threads et plusieurs instances de {mdt}, et qu'il faut toujours pouvoir arrêter les différentes instances.

== La nouvelle boucle de traitement des workers

Le fonctionnement actuel des worker est celui-ci{nbsp}:

ifeval::["{backend}" == "docbook5"]
image::workflow_7_1.svg[scaledwidth=50%,align="center"]
endif::[]
ifeval::["{backend}" != "docbook5"]
image::{article-07-url}/workflow_7_1.svg[scaledwidth=50%,align="center"]
endif::[]

La demande d'arrêt du moteur et l'absence de tâche à exécuter mènent tous les deux à l'arrêt du worker.

Il faut ajouter une nouvelle boucle dans le schéma{nbsp}: en l'absence de tâche, au lieu de s'arrêter les workers doivent se mettre en pause en attendant une notification.

Lorsqu'on les réveille, ils vérifient que le moteur est toujours en fonctionnement, et dans ce cas se remettent à chercher une tâche.

ifeval::["{backend}" == "docbook5"]
image::workflow_7_2.svg[scaledwidth=50%,align="center"]
endif::[]
ifeval::["{backend}" != "docbook5"]
image::{article-07-url}/workflow_7_2.svg[scaledwidth=50%,align="center"]
endif::[]

On pourrait vouloir directement passer de la pause au fait de chercher des tâches à exécuter{nbsp}:

ifeval::["{backend}" == "docbook5"]
image::workflow_7_3.svg[scaledwidth=50%,align="center"]
endif::[]
ifeval::["{backend}" != "docbook5"]
image::{article-07-url}/workflow_7_3.svg[scaledwidth=50%,align="center"]
endif::[]

Mais dans ce cas, si le worker ne trouve pas de tâche à exécuter après avoir réveillé il ne peut pas s'arrêter mais seulement se remettre en sommeil, à moins d'ajouter du code spécifique pour cela.

La proposition précédente est donc un peu plus générique.

Pour implémenter le workflow, on peut utiliser une double boucle{nbsp}:

- la boucle extérieur vérifie l'extinction du moteur, et est déclenchée au réveil
- la boucle intérieur vérifier l'extinction et cherche la prochaine tâche, et est exécutée à chaque tâche

.task_engine.rb
[source,ruby]
----
module TaskEngine
  class Worker
    def execute
      while @engine.status == Engine::ENGINE_STATUS_RUNNING
        while (@engine.status == Engine::ENGINE_STATUS_RUNNING) && (task = try_acquire_task)
          # Execute the task
        end
        # Wait until the notification awakes the worker
        LOGGER.info("Worker #{@worker_index} is sleeping")
        # We don't care about the message we got from the queue
        # since we just want to be awaken
        @engine.queue.pop
        LOGGER.info("Worker #{@worker_index} is awaken")
      end
      LOGGER.info("Worker #{@worker_index} is stopping")
    end
  end
end
----

== Envoyer une notification ou le contenu d'une tâche

Dans le modèle que je décris, le {mdt} reçoit des notification l'informant qu'une tâche devient disponible et il doit ensuite acquérir la tâche dans la base de données, et en passant récupérer les paramètres d'exécution.

Cela vient du fait que dans le système de notification de PostgreSQL les notifications sont envoyées à toutes les instances qui sont à l'écoute.

D'autres système de messages (par exemple ActiveMQ) permettent que chaque message ne soit reçu que par une instance au plus.
Dans ce cas l'acquisition de la tâche et la récupération des paramètres sont concentrés en une seule action{nbsp}: un {mdt} qui reçoit un message sait qu'il est le seul dans ce cas et peut donc directement exécuter la tâche.

Pour reprendre le vocabulaire de la partie 3, les systèmes de message comme ActiveMQ peuvent fournir du "`__exactly once__`".
Comme indiqué dans la partie 3, ce type de mécanisme est très difficile à mettre en œuvre de manière fiable, et en cas de crash du bus de message il y a des chances (même si elles sont faibles) que vous receviez le même message deux fois, il faut donc être préparé à cette éventualité.

== Pourquoi ne pas utiliser une `id` pour récupérer la prochaine tâche{nbsp}?

Lors de la création d'une tâche, le code connaît la tâche à créer et ses paramètres.

On pourrait vouloir utiliser ces informations pour simplifier l'acquisition de tâches{nsbp}: quand réveille un worker, au lieu de chercher la prochaine tâche à exécuter avec la requête existante, il pourrais plutôt chercher la tâche par son `id` une requête qui cherche si la tâche avec un certain `id` est toujours disponible.
Cette requête devrait être plus rapide.

Malheureusement cette solution n'est pas adaptée au fait d'avoir plusieurs {mdts} qui s'exécutent simultanément quand plusieurs tâches sont crées.

Si du code créé deux tâches T1 et T2.

Une instance M1 du {mdt} reçoit la notification pour T1 et dispose d'un worker en sommeil, il va alors le réveiller, et réussir à l'acquérir et donc à l'exécuter.

Une autre instance M2 du {mdt} reçoit également la notification pour T1 et dispose lui-aussi d'un worker en sommeil, il va alors le réveiller et ne pourra pas l'acquérir vu que M1 l'a déjà fait.

ifeval::["{backend}" == "docbook5"]
image::one_task.svg[scaledwidth=50%,align="center"]
endif::[]
ifeval::["{backend}" != "docbook5"]
image::{article-07-url}/one_task.svg[scaledwidth=50%,align="center"]
endif::[]

Si la notification pour T2 arrive entre le moment où 





- le premier c'est que quand plusieurs instances de {mdt} sont en cours d'exécution, 


Cela explique pourquoi un worker qui est réveillé par une notification va chercher la prochaine tâche à exécuter, plutôt que d'essayer d'acquérir la tâche qui correspond à la notification, par exemple en la cherchant par son `id`.
Si on cherchait la tâche pas son `id`, la requête serait plus rapide, mais elle ne serait efficace que pour le {mdt} qui réussi à l'acquérir.

Les autres instances du moteur qui feraient la requête par `id`ensuite se remettraient en sommeil immédiatement faute de tâche à exécuter.






Lors de la création d'une tâche, le code connaît la tâche à créer et ses paramètres.

On pourrait vouloir utiliser ces informations dans le worker, pour simplifier l'acquisition de tâches.
Au lieu de chercher la prochaine tâche à exécuter, le code pourrait plutôt chercher si la tâche avec un certain `id` est toujours disponible, ce qui rendrait la requête plus rapide.

Mais il faut se rappeller que le code du {mdt} doit bien fonctionner avec plusieurs instances.

Je vais prendre l'exemple de deux instance de {mdt} M1 et M2, avec chacune un worker disponible.

=== Une seule tâche

Si une seule tâche T1 est créée.

M1 et M2 recevront tous les deux la notification de création.
Les deux instances vont tenter de s'approprier T1, si c'est M1 qui réussi à l'acquérier, alors M2 ne trouvera aucune tâche disponible et se mettra en pause.

Le comportement est le même qu'on cherche T1 en utilisant la requête générique ou en cherchant par son `id`.
Dans ce cas la rechercher par `id` serait donc préférable car plus rapide.

ifeval::["{backend}" == "docbook5"]
image::one_task.svg[scaledwidth=50%,align="center"]
endif::[]
ifeval::["{backend}" != "docbook5"]
image::{article-07-url}/one_task.svg[scaledwidth=50%,align="center"]
endif::[]

== Deux tâches

Si deux tâches T1 et T2 sont créées.
M1 et M2 reçoivent les deux notifications de création .



Les deux vont tenter de s'approprier T1, si c'est à nouveau M1, alors M2 trouvera aucune tâche disponible et se mettra en pause.

Si la notification pour T2 arrive pendant que M2 cherche T1 par son `id`, alors la notification ne sera peut-être pas prise en compte si aucun worker de M2 n'est disponible, et si la notification arrive ensuite, M2 devra faire uen deuxième requête pour récupérer T2.




== La partie notification

== Notifications et transations


''''

Dans la partie suivante je vais ajouter un premier niveau de monitoring pour pouvoir commencer à suivre ce qui se passe.